<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Detection - SDV Robot</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<nav>
    <div class="nav-container">
        <a href="index.html" class="logo"><img src="keti.png" alt="KETI">SDV <span>Robot</span></a>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="hardware.html">Hardware</a></li>
            <li><a href="slam.html">SLAM</a></li>
            <li><a href="navigation.html">Navigation</a></li>
            <li><a href="ai.html" class="active">AI Detection</a></li>
            <li><a href="architecture.html">Architecture</a></li>
        </ul>
    </div>
</nav>

<header>
    <h1>AI Detection</h1>
    <p class="subtitle">YOLOv8 + TensorRT ì‹¤ì‹œê°„ ê°ì²´ ì¸ì‹</p>
</header>

<div class="container">

<section>
    <h2>Overview</h2>
    <p>SDV Robotì€ <strong>YOLOv8</strong>ì„ <strong>NVIDIA TensorRT</strong>ë¡œ ìµœì í™”í•˜ì—¬ ì‹¤ì‹œê°„ ê°ì²´ ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Jetson Orin Nanoì˜ GPUë¥¼ í™œìš©í•´ <strong>147 FPS</strong>ì˜ ê³ ì† ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>

    <div class="stats">
        <div class="stat">
            <div class="stat-value">147</div>
            <div class="stat-label">FPS</div>
        </div>
        <div class="stat">
            <div class="stat-value">7.6</div>
            <div class="stat-label">ms Latency</div>
        </div>
        <div class="stat">
            <div class="stat-value">80</div>
            <div class="stat-label">Classes</div>
        </div>
        <div class="stat">
            <div class="stat-value">9</div>
            <div class="stat-label">MB Engine</div>
        </div>
    </div>

    <div class="info-box">
        <strong>YOLO (You Only Look Once)</strong>: ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆë§Œ ë³´ê³  ê°ì²´ì˜ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ë¥¼ ë™ì‹œì— ì˜ˆì¸¡í•˜ëŠ” ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
    </div>
</section>

<section>
    <h2>YOLOv8 Architecture</h2>
    <p>YOLOv8ì€ Ultralyticsì—ì„œ ê°œë°œí•œ ìµœì‹  ë²„ì „ìœ¼ë¡œ, ë†’ì€ ì •í™•ë„ì™€ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>

    <div class="diagram">
     YOLOv8 Network Architecture
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

     Input Image (640Ã—640)
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                         Backbone (CSPDarknet)                    â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”          â”‚
     â”‚  â”‚Conv  â”‚ â†’ â”‚C2f   â”‚ â†’ â”‚Conv  â”‚ â†’ â”‚C2f   â”‚ â†’ â”‚SPPF  â”‚          â”‚
     â”‚  â”‚3Ã—3   â”‚   â”‚Block â”‚   â”‚3Ã—3   â”‚   â”‚Block â”‚   â”‚      â”‚          â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜          â”‚
     â”‚     â†“          â†“          â†“          â†“          â†“               â”‚
     â”‚   P1/2       P2/4       P3/8      P4/16      P5/32             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚           â”‚           â”‚
            â–¼           â–¼           â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                           Neck (PANet)                           â”‚
     â”‚                  Feature Pyramid + Bottom-up                     â”‚
     â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
     â”‚            â”‚ Upsample â”‚ â† Concat â† Downsample                   â”‚
     â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚           â”‚           â”‚
            â–¼           â–¼           â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                         Head (Decoupled)                         â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
     â”‚  â”‚ Small (P3)  â”‚  â”‚ Medium (P4) â”‚  â”‚ Large (P5)  â”‚              â”‚
     â”‚  â”‚ 80Ã—80Ã—(4+80)â”‚  â”‚ 40Ã—40Ã—(4+80)â”‚  â”‚ 20Ã—20Ã—(4+80)â”‚              â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                      Post-processing                             â”‚
     â”‚              NMS (Non-Maximum Suppression)                       â”‚
     â”‚                          â”‚                                       â”‚
     â”‚                          â–¼                                       â”‚
     â”‚              Detections: [x, y, w, h, class, confidence]        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    </div>

    <h3>ì£¼ìš” ì»´í¬ë„ŒíŠ¸</h3>
    <div class="cards">
        <div class="card nvidia">
            <h3>Backbone</h3>
            <p>íŠ¹ì§• ì¶”ì¶œê¸°</p>
            <ul>
                <li>CSPDarknet53 ê¸°ë°˜</li>
                <li>C2f (Cross Stage Partial)</li>
                <li>SPPF (Spatial Pyramid Pooling Fast)</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>Neck</h3>
            <p>ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•©</p>
            <ul>
                <li>PANet (Path Aggregation Network)</li>
                <li>FPN (Feature Pyramid Network)</li>
                <li>Top-down + Bottom-up</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>Head</h3>
            <p>ì˜ˆì¸¡ í—¤ë“œ</p>
            <ul>
                <li>Decoupled Head (ë¶„ë¦¬ëœ ë¶„ë¥˜/íšŒê·€)</li>
                <li>Anchor-free ë°©ì‹</li>
                <li>3ê°œ ìŠ¤ì¼€ì¼ ì¶œë ¥</li>
            </ul>
        </div>
    </div>
</section>

<section>
    <h2>Object Detection Algorithm</h2>

    <div class="algorithm-box">
        <h4>YOLO Detection Pipeline</h4>
        <ol>
            <li><strong>ì „ì²˜ë¦¬ (Preprocessing)</strong>
                <ul>
                    <li>ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (640Ã—640)</li>
                    <li>ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼ë§)</li>
                    <li>BGR â†’ RGB ë³€í™˜</li>
                </ul>
            </li>
            <li><strong>ì¶”ë¡  (Inference)</strong>
                <ul>
                    <li>TensorRT ì—”ì§„ìœ¼ë¡œ GPU ì¶”ë¡ </li>
                    <li>3ê°œ ìŠ¤ì¼€ì¼ì—ì„œ ì˜ˆì¸¡ (80Ã—80, 40Ã—40, 20Ã—20)</li>
                    <li>ê° ê·¸ë¦¬ë“œ ì…€ì—ì„œ ê°ì²´ ì˜ˆì¸¡</li>
                </ul>
            </li>
            <li><strong>í›„ì²˜ë¦¬ (Post-processing)</strong>
                <ul>
                    <li>Confidence ì„ê³„ê°’ í•„í„°ë§ (>0.5)</li>
                    <li>NMSë¡œ ì¤‘ë³µ ì œê±° (IoU >0.45)</li>
                    <li>ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜</li>
                </ul>
            </li>
        </ol>
    </div>

    <h3>Bounding Box Prediction</h3>
    <div class="diagram">
     Grid-based Detection
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

     â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
     â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
     â”‚   â”‚   â”‚   â”‚ â— â”‚ â— â”‚   â”‚   â”‚   â”‚  â— = ê·¸ë¦¬ë“œ ì…€ (ì˜ˆì¸¡ ë‹´ë‹¹)
     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
     â”‚   â”‚   â”‚ â”Œâ”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â” â”‚   â”‚   â”‚
     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”¤ â”‚   â”‚   â”‚ â”œâ”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   â”‚   â”‚ â”‚ â”‚ ğŸ•â”‚   â”‚ â”‚ â”‚   â”‚   â”‚  â”‚ Detected  â”‚
     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”¤ â”‚   â”‚   â”‚ â”œâ”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â”‚  Object   â”‚
     â”‚   â”‚   â”‚ â””â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”˜ â”‚   â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
     â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
     â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

     ê° ê·¸ë¦¬ë“œ ì…€ì€ ì˜ˆì¸¡:
       - (x, y, w, h) : ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
       - confidence   : ê°ì²´ ì¡´ì¬ í™•ë¥ 
       - class[80]    : í´ë˜ìŠ¤ë³„ í™•ë¥ 
    </div>

    <h3>Non-Maximum Suppression (NMS)</h3>
    <div class="algorithm-box">
        <h4>NMS Algorithm</h4>
        <p>ì¤‘ë³µëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì œê±°í•˜ì—¬ ìµœì¢… ê²€ì¶œ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.</p>
        <ol>
            <li>ëª¨ë“  ë°•ìŠ¤ë¥¼ confidence ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬</li>
            <li>ê°€ì¥ ë†’ì€ confidence ë°•ìŠ¤ ì„ íƒ</li>
            <li>ì„ íƒëœ ë°•ìŠ¤ì™€ IoU > 0.45ì¸ ë°•ìŠ¤ë“¤ ì œê±°</li>
            <li>ë‚¨ì€ ë°•ìŠ¤ ì¤‘ ë‹¤ìŒìœ¼ë¡œ ë†’ì€ confidence ë°•ìŠ¤ ì„ íƒ</li>
            <li>ëª¨ë“  ë°•ìŠ¤ê°€ ì²˜ë¦¬ë  ë•Œê¹Œì§€ ë°˜ë³µ</li>
        </ol>
        <div class="highlight">
            <strong>IoU (Intersection over Union)</strong> = êµì§‘í•© ë©´ì  / í•©ì§‘í•© ë©´ì 
        </div>
    </div>
</section>

<section>
    <h2>TensorRT Optimization</h2>
    <p><strong>NVIDIA TensorRT</strong>ëŠ” ë”¥ëŸ¬ë‹ ì¶”ë¡ ì„ ìµœì í™”í•˜ëŠ” SDKë¡œ, Jetsonì—ì„œ ìµœëŒ€ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.</p>

    <div class="cards">
        <div class="card nvidia">
            <h3>Layer Fusion</h3>
            <p>ë ˆì´ì–´ ê²°í•©</p>
            <ul>
                <li>Conv + BatchNorm + ReLU í†µí•©</li>
                <li>ë©”ëª¨ë¦¬ ì ‘ê·¼ ìµœì†Œí™”</li>
                <li>ì»¤ë„ í˜¸ì¶œ ê°ì†Œ</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>Precision Calibration</h3>
            <p>ì •ë°€ë„ ìµœì í™”</p>
            <ul>
                <li>FP32 â†’ FP16 ë³€í™˜</li>
                <li>2ë°° ë¹ ë¥¸ ì—°ì‚°</li>
                <li>ì •í™•ë„ ìœ ì§€</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>Kernel Auto-tuning</h3>
            <p>ì»¤ë„ ìµœì í™”</p>
            <ul>
                <li>í•˜ë“œì›¨ì–´ë³„ ìµœì  ì»¤ë„ ì„ íƒ</li>
                <li>GPU ì‚¬ìš©ë¥  ê·¹ëŒ€í™”</li>
                <li>ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ìµœì í™”</li>
            </ul>
        </div>
    </div>

    <h3>TensorRT ë³€í™˜ ê³¼ì •</h3>
    <div class="flow">
        <div class="flow-item">PyTorch Model<br>(.pt)</div>
        <div class="flow-arrow">â†’</div>
        <div class="flow-item">ONNX<br>(.onnx)</div>
        <div class="flow-arrow">â†’</div>
        <div class="flow-item nvidia">TensorRT Engine<br>(.engine)</div>
    </div>

<pre>
# YOLOv8 TensorRT ë³€í™˜ ëª…ë ¹ì–´
yolo export model=yolov8n.pt format=engine device=0 half=True
</pre>

    <h3>ì„±ëŠ¥ ë¹„êµ</h3>
    <table>
        <tr><th>Framework</th><th>Precision</th><th>FPS</th><th>Latency</th></tr>
        <tr><td>PyTorch</td><td>FP32</td><td>~25</td><td>~40ms</td></tr>
        <tr><td>TensorRT</td><td>FP32</td><td>~80</td><td>~12ms</td></tr>
        <tr><td><strong>TensorRT</strong></td><td><strong>FP16</strong></td><td><strong>147</strong></td><td><strong>7.6ms</strong></td></tr>
    </table>

    <div class="success-box">
        <strong>ì„±ëŠ¥ í–¥ìƒ</strong>: TensorRT FP16 ìµœì í™”ë¡œ PyTorch ëŒ€ë¹„ ì•½ 6ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
    </div>
</section>

<section>
    <h2>Detected Classes (COCO Dataset)</h2>
    <p>YOLOv8ì€ COCO ë°ì´í„°ì…‹ì˜ 80ê°œ í´ë˜ìŠ¤ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.</p>

    <div class="grid-3">
        <div>
            <h4>ì‚¬ëŒ & ë™ë¬¼</h4>
            <ul>
                <li>person (ì‚¬ëŒ)</li>
                <li>bicycle, car, motorcycle</li>
                <li>airplane, bus, train</li>
                <li>dog, cat, horse</li>
                <li>bird, cow, sheep</li>
            </ul>
        </div>
        <div>
            <h4>ìƒí™œìš©í’ˆ</h4>
            <ul>
                <li>chair, couch, bed</li>
                <li>dining table</li>
                <li>toilet, tv, laptop</li>
                <li>cell phone, keyboard</li>
                <li>refrigerator, oven</li>
            </ul>
        </div>
        <div>
            <h4>ìŒì‹ & ê¸°íƒ€</h4>
            <ul>
                <li>bottle, cup, fork</li>
                <li>knife, spoon, bowl</li>
                <li>banana, apple, orange</li>
                <li>pizza, cake, donut</li>
                <li>backpack, umbrella</li>
            </ul>
        </div>
    </div>

    <div class="warning-box">
        <strong>ì•ˆì „ ê¸°ëŠ¥</strong>: "person" í´ë˜ìŠ¤ê°€ ê°ì§€ë˜ë©´ ë¡œë´‡ì´ ìë™ìœ¼ë¡œ ì •ì§€í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    </div>
</section>

<section>
    <h2>Implementation</h2>

    <h3>Detection Pipeline Code</h3>
<pre>
# yolo_detector.py í•µì‹¬ ë¡œì§

class YoloDetector:
    def __init__(self):
        # TensorRT ì—”ì§„ ë¡œë“œ
        self.model = YOLO('yolov8n.engine')

    def detect(self, frame):
        # ì¶”ë¡  ì‹¤í–‰
        results = self.model(frame, conf=0.5, iou=0.45)

        detections = []
        for r in results:
            for box in r.boxes:
                x1, y1, x2, y2 = box.xyxy[0]
                confidence = box.conf[0]
                class_id = int(box.cls[0])
                class_name = self.model.names[class_id]

                detections.append({
                    'class': class_name,
                    'confidence': float(confidence),
                    'bbox': [int(x1), int(y1), int(x2), int(y2)]
                })

                # ì‚¬ëŒ ê°ì§€ ì‹œ ì •ì§€ ëª…ë ¹
                if class_name == 'person':
                    self.stop_robot()

        return detections
</pre>

    <h3>ì›¹ UI í‘œì‹œ</h3>
    <div class="diagram">
     Web UI Detection Display
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  [Control]  [Map]  [Clean]  [AI â—]                              â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                                                 â”‚
     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
     â”‚    â”‚                                                     â”‚     â”‚
     â”‚    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚     â”‚
     â”‚    â”‚    â”‚ ğŸ§‘ person    â”‚ â† ë°”ìš´ë”© ë°•ìŠ¤                   â”‚     â”‚
     â”‚    â”‚    â”‚   95%        â”‚   + í´ë˜ìŠ¤ëª…                    â”‚     â”‚
     â”‚    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   + ì‹ ë¢°ë„                      â”‚     â”‚
     â”‚    â”‚                                                     â”‚     â”‚
     â”‚    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚     â”‚
     â”‚    â”‚                    â”‚ ğŸª‘ chair   â”‚                  â”‚     â”‚
     â”‚    â”‚                    â”‚   87%       â”‚                  â”‚     â”‚
     â”‚    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚     â”‚
     â”‚    â”‚                                                     â”‚     â”‚
     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
     â”‚                                                                 â”‚
     â”‚    FPS: 147 | Detections: 2 | person, chair                    â”‚
     â”‚                                                                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    </div>
</section>

<section>
    <h2>Complete Pipeline</h2>
    <p>SDV Robotì˜ YOLO íŒŒì´í”„ë¼ì¸ì€ <strong>CompressedImage</strong>ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ì„ ìµœì í™”í•©ë‹ˆë‹¤.</p>

    <div class="diagram">
     YOLO Detection Pipeline (Full Data Flow)
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                              CAMERA LAYER                                    â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
     â”‚  â”‚   IMX219     â”‚ â”€â”€â–¶ â”‚  GStreamer   â”‚ â”€â”€â–¶ â”‚  nvjpegenc (Hardware)      â”‚  â”‚
     â”‚  â”‚   Sensor     â”‚     â”‚  Pipeline    â”‚     â”‚  JPEG Compression          â”‚  â”‚
     â”‚  â”‚  640Ã—360     â”‚     â”‚              â”‚     â”‚  Quality: 85%              â”‚  â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
     â”‚                                                        â”‚                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                /camera/image_raw/compressed  â”‚ CompressedImage
                                     (~50KB per frame)        â”‚
                                                              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                           YOLO DETECTOR NODE                                 â”‚
     â”‚                                                                              â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â”‚  â”‚  1. JPEG Decompress (cv2.imdecode)                                   â”‚   â”‚
     â”‚  â”‚     â””â”€â–¶ np.frombuffer(msg.data) â†’ cv2.imdecode(IMREAD_COLOR)         â”‚   â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
     â”‚                              â”‚                                               â”‚
     â”‚                              â–¼                                               â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â”‚  â”‚  2. Preprocess (Ultralytics)                                         â”‚   â”‚
     â”‚  â”‚     â””â”€â–¶ Resize 640Ã—640 â†’ Normalize â†’ BGRâ†’RGB â†’ NCHW tensor          â”‚   â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
     â”‚                              â”‚                                               â”‚
     â”‚                              â–¼                                               â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â”‚  â”‚  3. TensorRT Inference (GPU)                                         â”‚   â”‚
     â”‚  â”‚     â””â”€â–¶ yolov8n.engine (FP16) â†’ 6.8ms â†’ Raw predictions              â”‚   â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
     â”‚                              â”‚                                               â”‚
     â”‚                              â–¼                                               â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â”‚  â”‚  4. Postprocess (NMS + Filter)                                       â”‚   â”‚
     â”‚  â”‚     â””â”€â–¶ conf > 0.5 â†’ IoU NMS â†’ Bounding boxes + Classes              â”‚   â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
     â”‚                              â”‚                                               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚                     â”‚
              â–¼                     â–¼                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ /detections  â”‚      â”‚/person_targetâ”‚      â”‚ /yolo/debug  â”‚
     â”‚   (JSON)     â”‚      â”‚   (Point)    â”‚      â”‚   (Image)    â”‚
     â”‚              â”‚      â”‚ x,y position â”‚      â”‚  with boxes  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                              WEB UI                                          â”‚
     â”‚  rosbridge (9090) â”€â”€â–¶ JSON.parse â”€â”€â–¶ Canvas overlay (bounding boxes)        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    </div>

    <div class="success-box">
        <strong>CompressedImage ì‚¬ìš©</strong>: ì¹´ë©”ë¼ëŠ” <code>nvjpegenc</code>ë¡œ í•˜ë“œì›¨ì–´ JPEG ì••ì¶•ì„ ìˆ˜í–‰í•˜ê³ , YOLO ë…¸ë“œëŠ” <code>/camera/image_raw/compressed</code>ë¥¼ êµ¬ë…í•©ë‹ˆë‹¤. Raw ì´ë¯¸ì§€ ëŒ€ë¹„ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ~90% ì ˆê°!
    </div>

    <h3>Pipeline Latency Breakdown</h3>
    <table>
        <tr><th>Stage</th><th>Time</th><th>Notes</th></tr>
        <tr><td>JPEG Decompress</td><td>~0.3 ms</td><td>cv2.imdecode (CPU)</td></tr>
        <tr><td>Preprocess</td><td>~0.5 ms</td><td>Resize, normalize (CPU)</td></tr>
        <tr><td>TensorRT Inference</td><td>~6.8 ms</td><td>GPU FP16</td></tr>
        <tr><td>NMS Postprocess</td><td>~0.3 ms</td><td>Filter boxes (CPU)</td></tr>
        <tr><td><strong>Total</strong></td><td><strong>~7.6 ms</strong></td><td>147 FPS theoretical</td></tr>
    </table>
</section>

<section>
    <h2>ROS2 Topics</h2>

    <table>
        <tr><th>Topic</th><th>Type</th><th>Description</th></tr>
        <tr><td><code>/camera/image_raw/compressed</code></td><td>CompressedImage</td><td>JPEG ì••ì¶• ì´ë¯¸ì§€ (ì…ë ¥)</td></tr>
        <tr><td><code>/detections</code></td><td>String (JSON)</td><td>ê²€ì¶œ ê²°ê³¼</td></tr>
        <tr><td><code>/person_detected</code></td><td>Bool</td><td>ì‚¬ëŒ ê°ì§€ í”Œë˜ê·¸</td></tr>
        <tr><td><code>/person_target</code></td><td>Point</td><td>ì‚¬ëŒ ìœ„ì¹˜ (-1~1 ì •ê·œí™”)</td></tr>
        <tr><td><code>/person_distance</code></td><td>Float32</td><td>ì¶”ì • ê±°ë¦¬ (m)</td></tr>
        <tr><td><code>/yolo/debug</code></td><td>Image</td><td>ë°”ìš´ë”©ë°•ìŠ¤ í¬í•¨ ë””ë²„ê·¸ ì´ë¯¸ì§€</td></tr>
        <tr><td><code>/robot/ai_mode</code></td><td>String</td><td>AI ëª¨ë“œ ì œì–´ (yolo/off)</td></tr>
    </table>

    <h3>Detection Message Format</h3>
<pre>
{
    "timestamp": 1703001234.567,
    "frame_id": 12345,
    "fps": 147.2,
    "detections": [
        {
            "class": "person",
            "confidence": 0.95,
            "bbox": [100, 50, 300, 400]
        },
        {
            "class": "chair",
            "confidence": 0.87,
            "bbox": [400, 200, 550, 350]
        }
    ]
}
</pre>
</section>

<section>
    <h2>Performance Metrics</h2>

    <table>
        <tr><th>Metric</th><th>Value</th><th>Notes</th></tr>
        <tr><td>Model</td><td>YOLOv8n</td><td>Nano version (fastest)</td></tr>
        <tr><td>Input Size</td><td>640 Ã— 640</td><td>Square input</td></tr>
        <tr><td>Engine Size</td><td>9 MB</td><td>TensorRT FP16</td></tr>
        <tr><td>Throughput</td><td>147 FPS</td><td>Jetson Orin Nano</td></tr>
        <tr><td>Latency (mean)</td><td>7.6 ms</td><td>End-to-end</td></tr>
        <tr><td>GPU Compute</td><td>6.8 ms</td><td>GPU only</td></tr>
        <tr><td>CPU Time</td><td>0.8 ms</td><td>Pre/post processing</td></tr>
        <tr><td>mAP@0.5</td><td>37.3%</td><td>COCO val2017</td></tr>
    </table>

    <h3>Resource Usage</h3>
    <div class="grid-2">
        <div class="card nvidia">
            <h3>GPU</h3>
            <ul>
                <li>Usage: ~60%</li>
                <li>Memory: ~800 MB</li>
                <li>Power Mode: 15W</li>
            </ul>
        </div>
        <div class="card">
            <h3>CPU</h3>
            <ul>
                <li>Usage: ~20%</li>
                <li>Cores: 2/6 active</li>
                <li>Pre/post processing</li>
            </ul>
        </div>
    </div>
</section>

<section>
    <h2>OpenCV Feature Extensions</h2>
    <p>YOLO ì™¸ì—ë„ OpenCVë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

    <div class="cards">
        <div class="card primary">
            <h3>ğŸ¯ Object Following</h3>
            <p>ê°ì§€ëœ ê°ì²´ë¥¼ ì¶”ì í•˜ë©° ë”°ë¼ê°€ê¸°</p>
            <ul>
                <li>ì‚¬ëŒ/ë¬¼ì²´ ì¤‘ì‹¬ì  ì¶”ì </li>
                <li>PID ì œì–´ë¡œ ë¶€ë“œëŸ¬ìš´ ì¶”ì¢…</li>
                <li>ê±°ë¦¬ ìœ ì§€ (Bbox í¬ê¸° ê¸°ë°˜)</li>
            </ul>
        </div>
        <div class="card primary">
            <h3>âœ‹ Gesture Recognition</h3>
            <p>ì†ë™ì‘ìœ¼ë¡œ ë¡œë´‡ ì œì–´</p>
            <ul>
                <li>MediaPipe Hand Landmarks</li>
                <li>ì»¤ìŠ¤í…€ ì œìŠ¤ì²˜ ì •ì˜</li>
                <li>ì†ì§“ìœ¼ë¡œ ì´ë™/ì •ì§€ ëª…ë ¹</li>
            </ul>
        </div>
        <div class="card primary">
            <h3>ğŸ”´ Color Tracking</h3>
            <p>íŠ¹ì • ìƒ‰ìƒ ê°ì²´ ì¶”ì </p>
            <ul>
                <li>HSV ìƒ‰ê³µê°„ ë³€í™˜</li>
                <li>ë§ˆìŠ¤í¬ ê¸°ë°˜ í•„í„°ë§</li>
                <li>ì»¨íˆ¬ì–´ ê²€ì¶œ</li>
            </ul>
        </div>
        <div class="card primary">
            <h3>ğŸ›¤ï¸ Lane Following</h3>
            <p>ë°”ë‹¥ ë¼ì¸ ë”°ë¼ ì£¼í–‰</p>
            <ul>
                <li>Canny Edge Detection</li>
                <li>Hough Line Transform</li>
                <li>ì¡°í–¥ ê°ë„ ê³„ì‚°</li>
            </ul>
        </div>
    </div>

    <h3>Example: Object Following Implementation</h3>
<pre>
# object_follower.py - ì‚¬ëŒ ë”°ë¼ê°€ê¸° ì˜ˆì œ
import cv2
import numpy as np

class ObjectFollower:
    def __init__(self):
        self.target_distance = 1.0  # 1m ê±°ë¦¬ ìœ ì§€
        self.kp_linear = 0.5
        self.kp_angular = 1.0

    def follow(self, person_target, person_distance):
        """
        person_target: Point (x, y normalized -1 to 1)
        person_distance: estimated distance in meters
        """
        # Angular: turn toward person (x < 0 = left, x > 0 = right)
        angular_vel = -self.kp_angular * person_target.x

        # Linear: move forward/back to maintain distance
        distance_error = person_distance - self.target_distance
        linear_vel = self.kp_linear * distance_error

        # Clamp velocities
        linear_vel = np.clip(linear_vel, -0.2, 0.3)
        angular_vel = np.clip(angular_vel, -1.0, 1.0)

        return linear_vel, angular_vel
</pre>

    <h3>Example: Color Tracking</h3>
<pre>
# color_tracker.py - ë¹¨ê°„ìƒ‰ ë¬¼ì²´ ì¶”ì 
import cv2
import numpy as np

def track_red_object(frame):
    # Convert to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Red color range (wraps around 0)
    lower_red1 = np.array([0, 100, 100])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 100, 100])
    upper_red2 = np.array([180, 255, 255])

    # Create masks
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = mask1 + mask2

    # Find contours
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        # Get largest contour
        largest = max(contours, key=cv2.contourArea)
        if cv2.contourArea(largest) > 500:  # Min area filter
            M = cv2.moments(largest)
            cx = int(M['m10'] / M['m00'])
            cy = int(M['m01'] / M['m00'])
            return (cx, cy), mask

    return None, mask
</pre>

    <h3>Example: Gesture Control</h3>
<pre>
# gesture_control.py - ì†ë™ì‘ ì œì–´ (MediaPipe í•„ìš”)
import mediapipe as mp

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)

def detect_gesture(frame):
    """
    Returns:
    - 'stop': ì†ë°”ë‹¥ í¼ì¹¨ (5ì†ê°€ë½)
    - 'forward': ì£¼ë¨¹ (0ì†ê°€ë½)
    - 'left': ê²€ì§€ë§Œ ì™¼ìª½ ê°€ë¦¬í‚´
    - 'right': ê²€ì§€ë§Œ ì˜¤ë¥¸ìª½ ê°€ë¦¬í‚´
    - None: ì† ì—†ìŒ
    """
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    if not results.multi_hand_landmarks:
        return None

    hand = results.multi_hand_landmarks[0]

    # Count extended fingers
    fingers_up = count_fingers(hand)

    if fingers_up == 5:
        return 'stop'
    elif fingers_up == 0:
        return 'forward'
    elif fingers_up == 1:
        # Check index finger direction
        index_tip = hand.landmark[8]
        index_pip = hand.landmark[6]
        if index_tip.x < index_pip.x - 0.1:
            return 'left'
        elif index_tip.x > index_pip.x + 0.1:
            return 'right'

    return None
</pre>

    <h3>Example: Lane Following</h3>
<pre>
# lane_follower.py - ë¼ì¸ ë”°ë¼ê°€ê¸°
import cv2
import numpy as np

def detect_lane(frame):
    h, w = frame.shape[:2]

    # ROI: bottom half of image
    roi = frame[h//2:, :]

    # Convert to grayscale
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    # Gaussian blur
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    # Canny edge detection
    edges = cv2.Canny(blur, 50, 150)

    # Hough lines
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50,
                            minLineLength=50, maxLineGap=100)

    if lines is not None:
        # Calculate average line angle
        angles = []
        for line in lines:
            x1, y1, x2, y2 = line[0]
            angle = np.arctan2(y2 - y1, x2 - x1)
            angles.append(angle)

        avg_angle = np.mean(angles)

        # Convert to steering command
        # angle = 0: vertical line (go straight)
        # angle > 0: tilted right (turn right)
        steering = avg_angle * 2.0  # Gain
        return np.clip(steering, -1.0, 1.0)

    return 0.0  # No lines, go straight
</pre>
</section>

<section>
    <h2>Advanced AI Features</h2>
    <p>"ì‚¬ëŒ ë³´ê³  ë©ˆì¶”ê¸°"ë¥¼ ë„˜ì–´ì„œ, ë” ì¬ë¯¸ìˆëŠ” AI ê¸°ëŠ¥ë“¤ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

    <div class="cards">
        <div class="card nvidia">
            <h3>ğŸ• Pet Following</h3>
            <p>ë°˜ë ¤ë™ë¬¼ ë”°ë¼ë‹¤ë‹ˆê¸°</p>
            <ul>
                <li>YOLO class: dog, cat ì¶”ì </li>
                <li>Kalman Filterë¡œ ë¶€ë“œëŸ¬ìš´ ì¶”ì </li>
                <li>ê±°ë¦¬ ìœ ì§€í•˜ë©° ë”°ë¼ê°€ê¸°</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>ğŸ¾ Ball Chaser</h3>
            <p>ê³µ ì«“ì•„ê°€ê¸°</p>
            <ul>
                <li>sports ball í´ë˜ìŠ¤ ë˜ëŠ” ìƒ‰ìƒ ì¶”ì </li>
                <li>ê³µ ìœ„ì¹˜ë¡œ ìë™ ì´ë™</li>
                <li>ê³µì— ê°€ê¹Œì›Œì§€ë©´ ì •ì§€</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>ğŸš¶ Person Escort</h3>
            <p>ì‚¬ëŒ ì˜†ì—ì„œ ë™í–‰</p>
            <ul>
                <li>ì‚¬ëŒ ì˜† 1m ê±°ë¦¬ ìœ ì§€</li>
                <li>ì‚¬ëŒ ê±·ëŠ” ì†ë„ì— ë§ì¶¤</li>
                <li>ì¥ì• ë¬¼ íšŒí”¼í•˜ë©° ë™í–‰</li>
            </ul>
        </div>
        <div class="card nvidia">
            <h3>ğŸ¯ Object Finder</h3>
            <p>íŠ¹ì • ë¬¼ì²´ ì°¾ì•„ê°€ê¸°</p>
            <ul>
                <li>"ì»µì„ ì°¾ì•„ì¤˜" ëª…ë ¹ ì²˜ë¦¬</li>
                <li>íƒìƒ‰í•˜ë©° ë¬¼ì²´ ê²€ìƒ‰</li>
                <li>ë°œê²¬ ì‹œ í•´ë‹¹ ìœ„ì¹˜ë¡œ ì´ë™</li>
            </ul>
        </div>
    </div>

    <h3>Kalman Filter for Smooth Tracking</h3>
    <div class="info-box">
        <strong>ì™œ Kalman Filter?</strong> YOLO ê²€ì¶œì€ í”„ë ˆì„ë§ˆë‹¤ ì•½ê°„ì”© ë–¨ë¦½ë‹ˆë‹¤. Kalman Filterë¥¼ ì‚¬ìš©í•˜ë©´ ë¶€ë“œëŸ¬ìš´ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    </div>

<pre>
# kalman_tracker.py - ë¶€ë“œëŸ¬ìš´ ê°ì²´ ì¶”ì 
import numpy as np
from filterpy.kalman import KalmanFilter

class SmoothTracker:
    def __init__(self):
        self.kf = KalmanFilter(dim_x=4, dim_z=2)  # [x, y, vx, vy]

        # State transition matrix (constant velocity model)
        self.kf.F = np.array([
            [1, 0, 1, 0],
            [0, 1, 0, 1],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ])

        # Measurement matrix
        self.kf.H = np.array([
            [1, 0, 0, 0],
            [0, 1, 0, 0]
        ])

        # Measurement noise
        self.kf.R *= 10

        # Process noise
        self.kf.Q *= 0.1

        self.initialized = False

    def update(self, detection):
        """
        detection: (x, y) tuple or None if no detection
        Returns: smoothed (x, y) position
        """
        if detection is not None:
            if not self.initialized:
                self.kf.x = np.array([detection[0], detection[1], 0, 0])
                self.initialized = True
            else:
                self.kf.predict()
                self.kf.update(np.array(detection))
        else:
            if self.initialized:
                self.kf.predict()

        if self.initialized:
            return self.kf.x[0], self.kf.x[1]
        return None
</pre>
</section>

<section>
    <h2>Troubleshooting</h2>

    <table>
        <tr><th>Problem</th><th>Cause</th><th>Solution</th></tr>
        <tr><td>ë‚®ì€ FPS</td><td>ì˜ëª»ëœ ì—”ì§„ íŒŒì¼</td><td>TensorRT ì—”ì§„ ì¬ë¹Œë“œ</td></tr>
        <tr><td>ê°ì§€ ì•ˆë¨</td><td>ì¹´ë©”ë¼ ë¬¸ì œ</td><td>ì¹´ë©”ë¼ ì—°ê²° í™•ì¸</td></tr>
        <tr><td>ì˜¤íƒì§€ ë§ìŒ</td><td>ë‚®ì€ confidence</td><td>confidence ì„ê³„ê°’ ìƒí–¥</td></tr>
        <tr><td>ë©”ëª¨ë¦¬ ë¶€ì¡±</td><td>ì—”ì§„ í¬ê¸°</td><td>ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© (yolov8n)</td></tr>
        <tr><td>GPU ì˜¤ë¥˜</td><td>CUDA ë²„ì „</td><td>JetPack/TensorRT ë²„ì „ í™•ì¸</td></tr>
        <tr><td>ì¶”ì  ë–¨ë¦¼</td><td>YOLO ë…¸ì´ì¦ˆ</td><td>Kalman Filter ì ìš©</td></tr>
        <tr><td>ìƒ‰ìƒ ì¶”ì  ì‹¤íŒ¨</td><td>ì¡°ëª… ë³€í™”</td><td>HSV ë²”ìœ„ ì¡°ì •, ì ì‘í˜• ì„ê³„ê°’</td></tr>
    </table>
</section>

</div>

<footer>
    <p><strong>SDV Robot</strong> - AI Detection Documentation</p>
    <div class="footer-links">
        <a href="index.html">Home</a>
        <a href="hardware.html">Hardware</a>
        <a href="slam.html">SLAM</a>
        <a href="navigation.html">Navigation</a>
        <a href="architecture.html">Architecture</a>
    </div>
    <p style="margin-top: 20px;">Developed by <a href="https://www.keti.re.kr">KETI</a></p>
</footer>

</body>
</html>
